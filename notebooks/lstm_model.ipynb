{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model – Stock Price Prediction\n",
    "\n",
    "## Why LSTM?\n",
    "Standard feedforward networks treat each input independently. Stock prices are\n",
    "**sequential** – yesterday's price carries information about today's. Long Short-Term\n",
    "Memory (LSTM) networks contain gating mechanisms (forget, input, output gates) that\n",
    "learn *which* past information to retain, making them ideal for time-series.\n",
    "\n",
    "## Overfitting Prevention\n",
    "- **Dropout layers** randomly zero out neurons during training (regularisation).\n",
    "- **Batch Normalisation** stabilises activations layer by layer.\n",
    "- **Early Stopping** halts training when validation loss stops improving.\n",
    "- **ReduceLROnPlateau** decays the learning rate when learning stalls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data_loader import (\n",
    "    fetch_stock_data, time_series_split,\n",
    "    scale_features, build_sequences\n",
    ")\n",
    "from src.sentiment_analyzer import add_sentiment_to_df\n",
    "from src.model_trainer import train_lstm\n",
    "from src.evaluator import (\n",
    "    regression_metrics, plot_predictions,\n",
    "    plot_loss_curves, sharpe_ratio, max_drawdown\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Config ────────────────────────────────────────────────────────────────────\n",
    "TICKER     = 'AAPL'\n",
    "START      = '2015-01-01'\n",
    "END        = '2024-12-31'\n",
    "SEQ_LEN    = 60      # look-back window (trading days)\n",
    "TRAIN_RATIO = 0.80\n",
    "EPOCHS     = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Feature columns fed to LSTM (excluding target 'Close')\n",
    "FEATURE_COLS = [\n",
    "    'Open', 'High', 'Low', 'Volume',\n",
    "    'SMA_10', 'SMA_20', 'SMA_50',\n",
    "    'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "    'BB_Width', 'ATR_14', 'Vol_Change', 'Log_Return', 'Sentiment',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1. Load & Prepare Data ────────────────────────────────────────────────────\n",
    "df = fetch_stock_data(TICKER, START, END)\n",
    "df = add_sentiment_to_df(df, TICKER, START, END)\n",
    "\n",
    "# Remove any feature columns that weren't computed (edge-case)\n",
    "feature_cols = [c for c in FEATURE_COLS if c in df.columns]\n",
    "print(f'Using {len(feature_cols)} features')\n",
    "\n",
    "train_df, test_df = time_series_split(df, TRAIN_RATIO)\n",
    "print(f'Train: {len(train_df)} rows | Test: {len(test_df)} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 2. Scale Features (fit on train only!) ────────────────────────────────────\n",
    "# The target column 'Close' is appended last; target_idx = -1\n",
    "train_scaled, test_scaled, scaler = scale_features(\n",
    "    train_df, test_df, feature_cols, target_col='Close'\n",
    ")\n",
    "\n",
    "target_idx = len(feature_cols)   # last column = Close\n",
    "\n",
    "X_train, y_train = build_sequences(train_scaled, SEQ_LEN, target_idx)\n",
    "X_test,  y_test  = build_sequences(test_scaled,  SEQ_LEN, target_idx)\n",
    "\n",
    "print(f'X_train: {X_train.shape}  |  y_train: {y_train.shape}')\n",
    "print(f'X_test:  {X_test.shape}   |  y_test:  {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 3. Train LSTM ──────────────────────────────────────────────────────────────\n",
    "# We use 10 % of training data as validation for early stopping\n",
    "val_split  = int(len(X_train) * 0.9)\n",
    "X_val      = X_train[val_split:]\n",
    "y_val      = y_train[val_split:]\n",
    "X_train_   = X_train[:val_split]\n",
    "y_train_   = y_train[:val_split]\n",
    "\n",
    "model, history = train_lstm(\n",
    "    X_train_, y_train_,\n",
    "    X_val,    y_val,\n",
    "    units=64, dropout=0.2,\n",
    "    learning_rate=1e-3,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_path='../results/lstm_model.keras',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 4. Loss Curves ────────────────────────────────────────────────────────────\n",
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 5. Predictions & Inverse Transform ───────────────────────────────────────\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y_pred_scaled = model.predict(X_test).flatten()\n",
    "\n",
    "# Inverse-transform predictions back to USD\n",
    "# We need to reconstruct a full-width array then pick the Close column\n",
    "n_cols  = len(feature_cols) + 1   # features + Close\n",
    "\n",
    "def inverse_close(scaled_vals, scaler, close_col_idx, n_cols):\n",
    "    dummy = np.zeros((len(scaled_vals), n_cols))\n",
    "    dummy[:, close_col_idx] = scaled_vals\n",
    "    inv = scaler.inverse_transform(dummy)\n",
    "    return inv[:, close_col_idx]\n",
    "\n",
    "y_pred_usd = inverse_close(y_pred_scaled, scaler, target_idx, n_cols)\n",
    "y_true_usd = inverse_close(y_test,        scaler, target_idx, n_cols)\n",
    "\n",
    "# Dates for the test period (accounting for look-back)\n",
    "test_dates = test_df.index[SEQ_LEN:]\n",
    "\n",
    "metrics = regression_metrics(y_true_usd, y_pred_usd, 'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6. Plot Predictions ───────────────────────────────────────────────────────\n",
    "plot_predictions(y_true_usd, y_pred_usd, label='LSTM', dates=test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 7. Finance Metrics ────────────────────────────────────────────────────────\n",
    "# Simulate a simple strategy: buy when predicted > actual (upward signal)\n",
    "pred_returns  = np.diff(y_pred_usd) / (y_pred_usd[:-1] + 1e-10)\n",
    "actual_returns = np.diff(y_true_usd) / (y_true_usd[:-1] + 1e-10)\n",
    "\n",
    "# Signal: go long if model predicts price increase\n",
    "signals  = np.where(pred_returns > 0, 1, -1)\n",
    "strat_returns = signals * actual_returns\n",
    "\n",
    "print('\\n── LSTM Strategy Finance Metrics ───────────')\n",
    "sr  = sharpe_ratio(strat_returns)\n",
    "mdd = max_drawdown(np.cumprod(1 + strat_returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 8. Save metrics to results/ ──────────────────────────────────────────────\n",
    "import json, os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "metrics.update({'Sharpe': round(sr, 4), 'MaxDrawdown': round(mdd, 4)})\n",
    "with open('../results/lstm_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print('Metrics saved → ../results/lstm_metrics.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
